---
layout: tutorial_page
permalink: /genomic_epidemiology_2017_EPD_IMS
title: Genomic Epidemiology
header1: Emerging Pathogen Detection and Identification using Metagenomic Samples
header2: Infectious Disease Genomic Epidemiology
image: /site_images/CBW_wshop-epidem_map-icon.png
home: https://bioinformaticsdotca.github.io/genomic_epidemiology_2017
description: Emerging Pathogen Detection and Identification using Metagenomic Samples
author: Gary Van Domselaar
modified: May 3rd, 2017
---


## Table of contents
1. [Introduction](#intro)
2. [Software](#software)    
2. [Environment Setup](#env)
3. [Exercise 1](#ex1)
4. [Exercise 2](#ex2)
5. [Paper](#paper)

<a name="intro"></a>
## Introduction

This tutorial aims to introduce a variety of softwares and concepts related to how to detect emerging pathogens from a complex host sample. Each exercise will demonstrate some of the concepts in current routine use and hopefully be applied to future applications.

All datasets have been modified to either illustrate a specific learning objective or to reduce the complexity of the problem. Contamination and a lack of large and accurate databases render detection of microbial pathogens difficult. As a disclaimer, all results produced from the tools described in this tutorial and others must also be verified with supplementary bioinformatics or wet-laboratory techniques.

<a name="software"></a>
## List of software for tutorial

* [Kraken](https://ccb.jhu.edu/software/kraken/)
* [KAT](https://kat.readthedocs.io/en/latest/)
* [Krona](https://github.com/marbl/Krona/wiki)
* [SPAdes](http://cab.spbu.ru/software/spades/)
* [NCBI blast](https://blast.ncbi.nlm.nih.gov/Blast.cgi?PAGE_TYPE=BlastSearch)
 
To begin, we will setup our environment in our ~/workspace so we can view our progress using the web browser.

<a name="env"></a>
## Environment setup

```bash
export WORK_DIR=~/workspace/module6/

mkdir -p $WORK_DIR

cd $WORK_DIR

ln -s ~/CourseData/IDGE_data/EPD_IMS .

mkdir $WORK_DIR/ex1 $WORK_DIR/ex2 $WORK_DIR/ex3

```

<a name="ex1"></a>
## Exercise 1

### Patient Background:

On April 27, a 66-year old male was admitted to a local ER. He presented with fever, headache, and vomiting but soon after admission to the ER presented with internal bleeding. CBC revealed elevated white blood cell count, neutrophils, etc. The hospital epidemiologist was consulted to confirm the clinician's findings. 

### Demonstration:

* Filter host reads with KAT
* Run Kraken with small bacteria and viral database
* Generate text and graphic reports with Kraken and Krona

---

### Step 1: Host read filtering

The first step in this demonstration is to remove the host reads from the dataset prior to downstream analysis. There are several different tools that can be used to filter out host reads such as Kraken, BLAST, KAT and others. In this demonstration, we have selected KAT because of the smaller memory requirement compared to Kraken and relatively quick speed.

Command documentation is available [here](http://kat.readthedocs.io/en/latest/using.html#sequence-filtering)

KAT works by breaking down each read into k-mers fragments of length 27 and comparing them to a k-mer database of human reference genomes. Subsequently, the complete read is either assigned into a matched or unmatched file(s) if 10% of the k-mers in the read have been found in the human database. 

<img src="https://github.com/bioinformaticsdotca/Genomic_Epi_2017/blob/master/module6/images/kat.png?raw=true" alt="KAT" width="750" />  

```bash
cd ex1

kat filter seq -i -o unmatched --seq ex1_1.fastq --seq2 ex1_2.fastq ../../kat_db/human_kmers.jf
```

#### Command arguments:

* `--seq --seq2` arguments to provide corresponding forward and reverse fastq reads
* `-i` whether to output sequences not found in the kmer hash, rather than those with a database hit (host sequences). 
* `-o unmatched` Provide prefix for all files generated by the command. In our case, we will have two output files **unmatched.in.R1.fastq** and **unmatched.in.R2.fastq**.

After the above command is done running, you should see similar output on your screen as shown below.

If the command was successful, your current directory should contain two new files:

* unmatched.in.R1.fastq
* unmatched.in.R2.fastq

---

### Step 2: Classify reads against kraken database

Now that we have most, if not all, host reads filtered out, it’s time to classify the remaining reads.

Database selection is one of the most crucial parts of running Kraken. One of the many factors that must be considered are the computational resources available. Our current AWS image for the course has only 16G of memory. A major disadvantage of Kraken is that it loads the entire database into memory. With the full viral, bacterial, and archael database on the order of 100 GB we would be unable to run Kraken on the course machine (though the recently released Kraken 2 has done a lot to reduce database size). To help mitigate this, Kraken allows reduced databases to be constructed, which will still give reasonable results. We have constructed our own miniture Kraken database for this course, though a downloadable version is also provided by the authors: [minikraken](https://ccb.jhu.edu/software/kraken/dl/minikraken.tgz).

Lets run the following command in our current directory to classify our reads against the kraken database.

```bash
kraken --paired --threads 4 --db ../../module_data/kraken_db/ unmatched.in.R1.fastq unmatched.in.R2.fastq > results_initial.txt
```

After the above command is done running, you should see similar output on your screen as shown below.

```
110056 sequences (32.66 Mbp) processed in 13.748s (480.3 Kseq/m, 142.53 Mbp/m).
  90212 sequences classified (81.97%)
  19844 sequences unclassified (18.03%)
```

---

### Step 3: Generate text-based report using Kraken-report.

While this initial output file, `results_initial.txt`, is useful as input to some software, it is not really meant to be human readable. Lets convert this file to a human-readable format using `kraken-report`.

```bash
kraken-report --db ../../module_data/kraken_db/ results_initial.txt > results_final.txt
```

Let’s look at the generated text report from Kraken-report by opening a web browser on your laptop, and navigate to http://cbwXX.dyndns.info/, where XX is your student ID. You should be able to find the file in the following directory hierarchy `~/workspace/modules6/ex1/` and open file `final_report.txt`

The output of `kraken-report` is easier to understand and interpret than the previous output we generated from Kraken, but it is still not as interactive as it could be. Documentation for kraken-report is available [here](https://ccb.jhu.edu/software/kraken/MANUAL.html#sample-reports)

This is where Krona comes in. Krona generates an interactive html web page that allows hierarchical data to be explored with zooming, multi-layered pie charts and other added features.

---
### Step 4: Generate interactive html based report using Kraken-report.

```bash
cut -f2,3 results_initial.txt > krona_input.txt

ktImportTaxonomy krona_input.txt -o final_web_report.html
```

Let’s look at what Krona generated.

Return to your web browser and refresh the page from Step 3 to see the new files added in ~/workspace/modules6/ex1 directory.

Click on final_web_report.html and you should see the image below.

![krona_ex1](images/krona_ex1.png)

---
### Questions

1. Given the output of Krona, what do you hypothesize is causing the patient's illness?

---
<a name="ex2"></a>
## Exercise 2

### Background:

On April 24, a 5-year old female was admitted to a local ER. She presented with high fever, chills and enlarged lymph nodes. CBC revealed elevated white blood cell count, neutrophils, etc. The hospital epidemiologist was consulted to confirm the clinician's’ findings. 

### Demonstration:

* Filter host reads with KAT
* Run Kraken with small bacteria and viral database
* Generate text and graphic reports with Kraken and Krona
* Assemble reads and send to NCBI BLAST to check against additional database

---
### Step 1: Host read filtering

The first step in this demonstration is to remove the host reads from the dataset prior to downstream analyses.

```bash
cd ~/workspace/module6/ex2/

kat filter seq -i -o unmatched --seq ex2_1.fastq --seq2 ex2_2.fastq ../../module_data/kat_db/human_kmers.jf
```

---
### Step 2: Classify reads against bacterial kraken database

Now let's classify our reads against the kraken database. Please make sure to include `--classified-out` and `-unclassified-out` as we will make use of these files.

```bash
kraken --paired --threads 4 --db ../../module_data/kraken_db/ --classified-out classified.fasta --unclassified-out unclassified.fasta unmatched.in.R1.fastq unmatched.in.R2.fastq > results_initial.txt
```

Let's also construct a text report and a Krona chart.

```bash
kraken-report --db ../../module_data/kraken_db/ results_initial.txt > results_final.txt

cut -f2,3 results_initial.txt > krona_input.txt

ktImportTaxonomy krona_input.txt -o final_web_report.html
```

Now we can take a look at the text report and Krona chart from `~/workspace/modules6/ex2/bacterial_report.txt` in the web browser.

![image][]

Huh!? That's odd. It looks like ~20% of our reads are unclassified while ~80% of our reads belong to the subfamiliy [Coronavirinae](https://en.wikipedia.org/wiki/Coronavirinae), but not to any more specific taxonomic level. When Kraken classifies k-mers it will match them to the lowest commen ancestor of all genomes containing the k-mer, in this case to Coronovirinae. This could possibly indicate that the organism these reads belong to is not well-represented in our Kraken database (possibly an emerging pathogen).

One option to get a bit more information about what's going on would be to use a larger Kraken database, but this requires a lot more computer resources. Another option is to try and assemble these reads with [SPAdes][] and see if we can make any sense of them. Let's try this option.

SPAdes normally operates on reads in fastq format (sequence data plus quality scores), but kraken outputs the classified and unclassified reads in fasta format (no quality score information). Quality scores are useful for correcting possible errors in the reads, but we can still assemble reads into genomes without them and get reasonable results (assuming the reads already are relativly error-free). Let's do this now, disabling error correction with `--only-assembler`.

```
spades.py --only-assembler -s unclassified.fasta -o unclassified_results

spades.py --only-assembler -s classified.fasta -o classified_results
```

The assembled genomes will be located under `classified_results/contigs.fasta` and `unclassified_results/contigs.fasta`. In order to get a better idea of what's in these files, let's run them through [NCBI BLAST](https://blast.ncbi.nlm.nih.gov/Blast.cgi) and examine the matches.

### Questions

1. Look through the matches for the longest and highest-covered contigs in NCBI. Is there any matches more specific than *Coronovirinae*? What do you suppose is responsible for the patients illness?

   You can look through the results for different contigs in NCBI BLAST by using the drop-down menu shown below:

   ![blast-drop-down][images/]

## Paper

<a name="paper"></a>
[An evaluation of the accuracy and speed of metagenome analysis tools](https://www.nature.com/articles/srep19233)
